{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc38474-26ce-44d4-addb-8f3e8f5b625c",
   "metadata": {},
   "source": [
    "## A2: Task 2\n",
    "This is an exploration of task 2 described in the markdown. I'll try to use a TDD approach using [ipytest](https://github.com/chmp/ipytest) for my testing framework. I'll mainly be testing the \"hard parts\" and not stuff I'm confident in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51d19eb1-1967-4ae0-a82b-e531853183aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T07:52:25.704524Z",
     "iopub.status.busy": "2022-03-08T07:52:25.703963Z",
     "iopub.status.idle": "2022-03-08T07:52:26.226112Z",
     "shell.execute_reply": "2022-03-08T07:52:26.225435Z",
     "shell.execute_reply.started": "2022-03-08T07:52:25.704473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from pathlib import Path\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from typing import Sequence, Callable, List\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18074bca-3b26-4fbb-8d6e-dbcff112552f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T07:38:18.030344Z",
     "iopub.status.busy": "2022-03-08T07:38:18.029800Z",
     "iopub.status.idle": "2022-03-08T07:38:18.587272Z",
     "shell.execute_reply": "2022-03-08T07:38:18.586549Z",
     "shell.execute_reply.started": "2022-03-08T07:38:18.030294Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../../../CDS-LANG/tabular_examples/\")\n",
    "data_path = DATA_DIR / \"fake_or_real_news.csv\"\n",
    "df = pd.read_csv(data_path, index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "731bdee5-66a5-4dea-a035-4ed01e56e7b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T07:40:00.814842Z",
     "iopub.status.busy": "2022-03-08T07:40:00.814326Z",
     "iopub.status.idle": "2022-03-08T07:40:01.063860Z",
     "shell.execute_reply": "2022-03-08T07:40:01.063194Z",
     "shell.execute_reply.started": "2022-03-08T07:40:00.814792Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def extract_geopol(doc: Doc) -> str:\n",
    "    return \";\".join(ent.text for ent in doc.ents if ent.label_ == \"GPE\")\n",
    "\n",
    "def test_extract_geopol():\n",
    "    doc = nlp(\"Washington battling Russia\")\n",
    "    geopols = extract_geopol(doc)\n",
    "    assert geopols == \"Washington;Russia\"\n",
    "    \n",
    "def test_only_GPE():\n",
    "    doc = nlp(\"Why isn't Rihanna leading Denmark yet?\")\n",
    "    geopols = extract_geopol(doc)\n",
    "    assert geopols == \"Denmark\"\n",
    "    \n",
    "def test_no_GPE():\n",
    "    doc = nlp(\"what?\")\n",
    "    geopols = extract_geopol(doc)\n",
    "    assert geopols == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d44c0b7b-30b9-4ba1-8608-321fcf6a3f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T07:58:36.199875Z",
     "iopub.status.busy": "2022-03-08T07:58:36.199349Z",
     "iopub.status.idle": "2022-03-08T07:58:36.795427Z",
     "shell.execute_reply": "2022-03-08T07:58:36.794185Z",
     "shell.execute_reply.started": "2022-03-08T07:58:36.199827Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "# Testing multiple sentences\n",
    "def test_list_geopol():\n",
    "    docs = list(nlp.pipe([\"Denmark is a country\", \"Hello mr. smartypants\"]))\n",
    "    entities = list_geopol(docs)\n",
    "    assert entities[0] == \"Denmark\"\n",
    "    assert entities[1] == \"\"\n",
    "    \n",
    "def list_geopol(docs: Sequence[Doc]) -> List[str]:\n",
    "    return [extract_geopol(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9cae78-99ee-4d21-a57f-e088a1062b0e",
   "metadata": {},
   "source": [
    "## adding sentiment\n",
    "To make the script interoperable between textblob and VADER, I'll only look at \"compound\" sentiment for both. For the beginning I'll only investigate textblob as it is easier to integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e400aba4-e3e7-455b-97f9-324d1e5b3591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T07:45:41.914083Z",
     "iopub.status.busy": "2022-03-08T07:45:41.913411Z",
     "iopub.status.idle": "2022-03-08T07:45:42.064422Z",
     "shell.execute_reply": "2022-03-08T07:45:42.063746Z",
     "shell.execute_reply.started": "2022-03-08T07:45:41.914035Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "def textblob_sentiment(doc: Doc) -> float:\n",
    "    return doc._.blob.polarity\n",
    "\n",
    "def test_textblob():\n",
    "    doc = nlp(\"you are stupid and dumb :(\")\n",
    "    assert textblob_sentiment(doc) < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b1cc43-e295-4355-b208-bb5efbf0d4e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T07:53:02.943822Z",
     "iopub.status.busy": "2022-03-08T07:53:02.943298Z",
     "iopub.status.idle": "2022-03-08T07:53:03.097022Z",
     "shell.execute_reply": "2022-03-08T07:53:03.096392Z",
     "shell.execute_reply.started": "2022-03-08T07:53:02.943773Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "# Testing multiple sentiments\n",
    "def test_multiple_sentiment():\n",
    "    docs = list(nlp.pipe([\"I am angry!\", \"Happy days people\"]))\n",
    "    sentiments = list_sentiment(docs, sent_f=textblob_sentiment)\n",
    "    assert sentiments[0] < 0\n",
    "    assert sentiments[1] > 0\n",
    "    \n",
    "def list_sentiment(docs: Sequence[Doc], sent_f: Callable[[Doc], float]) -> List[float]:\n",
    "    return [sent_f(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc282af1-b72e-42e6-8000-84ed3d4aa104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T07:54:41.421587Z",
     "iopub.status.busy": "2022-03-08T07:54:41.421070Z",
     "iopub.status.idle": "2022-03-08T07:54:52.323051Z",
     "shell.execute_reply": "2022-03-08T07:54:52.321664Z",
     "shell.execute_reply.started": "2022-03-08T07:54:41.421538Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "headline_docs = list(nlp.pipe(df[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c230ec3c-313b-43ec-9df8-b1598ace07cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T07:59:30.790552Z",
     "iopub.status.busy": "2022-03-08T07:59:30.790023Z",
     "iopub.status.idle": "2022-03-08T07:59:31.748954Z",
     "shell.execute_reply": "2022-03-08T07:59:31.748222Z",
     "shell.execute_reply.started": "2022-03-08T07:59:30.790505Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "geopols = list_geopol(headline_docs)\n",
    "sentiments = list_sentiment(headline_docs, textblob_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "480bddeb-a205-4969-a130-1cb31e6945a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:05:52.784252Z",
     "iopub.status.busy": "2022-03-08T08:05:52.783697Z",
     "iopub.status.idle": "2022-03-08T08:05:52.794866Z",
     "shell.execute_reply": "2022-03-08T08:05:52.793847Z",
     "shell.execute_reply.started": "2022-03-08T08:05:52.784202Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    headline_docs = list(nlp.pipe(df[\"title\"]))\n",
    "    geopols = list_geopol(headline_docs)\n",
    "    sentiments = list_sentiment(headline_docs, textblob_sentiment)\n",
    "    return pd.DataFrame(zip(df[\"title\"], geopols, sentiments), columns = [\"title\", \"GPE\", \"sentiment\"])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
